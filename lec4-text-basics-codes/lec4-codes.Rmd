---
title: "Lecture 4 codes"
output: rmarkdown::github_document
---

## Preprocessing text data with quanteda

Let us check out an dataset containing [IMDB Movie Review Dataset](https://www.kaggle.com/columbine/imdb-dataset-sentiment-analysis-in-csv-format).
Some codes are borrowed from [Pablo Barbera](http://pablobarbera.com/text-analysis-vienna/code.html).


Before we can do any type of automated text analysis,  we will need to go through "preprocessing" steps. We'll use the `quanteda` package  [quanteda](https://github.com/kbenoit/quanteda) here.
The manual is [here](https://cran.r-project.org/web/packages/quanteda/quanteda.pdf).
The quick introduction is [here](https://quanteda.io/).


The basic unit of work for the `quanteda` package is called a `corpus`, which represents a collection of text documents with some associated metadata. Documents are the subunits of a corpus. You can use `summary` to get some information about your corpus.


In the terminology of `quanteda`, `type` means *unique* words. `Token` mean any word.

```{r, message=F}
library(quanteda)
library(data.table) # this package help you to read large files quicker
reviews <- fread("train.csv") # fread() is a function in data.table
```

Transform CSV file into a `corpus` object in `quanteda` package.
```{r}
twcorpus <- corpus(reviews$text)
summary(twcorpus, n=10)
```

A very useful feature of corpus objects is _keywords in context_, which returns all the appearances of a word (or combination of words) in its immediate context.

```{r}
kwic(x = twcorpus, pattern = "like", window=5, separator = ",")[1:5,]
```
document-feature matrix = document-term matrix

We can then convert a corpus into a document-feature matrix (document-term matrix) using the `dfm` function.
 
```{r}
doc.term <- dfm(x = twcorpus, verbose=TRUE)
doc.term
```

Similar to a normal matrix, the dimension of  document-term matrix in `quanteda` can be obtained by

```{r}
 dim(doc.term)
```

To see how frequent a word appears, just take sum the column. For instance, to get how many times the word `school` appears:

```{r}
which_column_num_is_school <- which(colnames(doc.term) == "school")
print (which_column_num_is_school)
print (sum(doc.term[,which_column_num_is_school]))
```

You can subset the document-term matrix using the following way:

```{r}
doc.term[1:5, 1:10]
```

Before running any function, you are *strongly recommended* to read its help function first. 
`dfm` has many useful options (check out `?dfm` or `help(dfm)` for more information). Let's actually use it to stem the text, extract n-grams, remove punctuation, keep Twitter features...

```{r}
doc.term <- dfm(twcorpus, tolower=TRUE, stem=TRUE, remove_punct = TRUE, remove_url=TRUE, verbose=TRUE)
doc.term
```

Note that here we use n-grams -- this will extract all combinations of one, two, and three words (e.g. it will consider both "human", "rights", and "human rights" as tokens in the matrix).

In `Quanteda`, stemming relies on the `SnowballC` package's implementation of the Porter stemmer:

```{r}

example <- tolower(reviews$text[1]) 
print (reviews$text[1])
print ("-----------Tokens")
token1 <- tokens(example) #token of the first document
print (token1) # only the first 10 was printed
```

What if we want to print more? The way to do this is to go to the reference manual, and search `print`. You will see additional options and find that specifying `max_ntoken` allow you to print more.
```{r}
print (token1, max_ntoken = 1000)
```

We check results after stemming
```{r}
print (token1)
print ("-----------Tokens after stemming")
tokens_wordstem(token1)
```


We can also see the results of n-grams of the first document. I use up to 3-gram in the below code.

```{r}
token1[[1]]
tk <- tokens_ngrams(token1, 1:3)
tk[[1]]
```

In a large corpus like this, many features often only appear in one or two documents. In some case it's a good idea to remove those features, to speed up the analysis or because they're not relevant. We can `trim` the dfm:

```{r}
doc.term <- dfm_trim(doc.term, min_docfreq=10, verbose=TRUE)
doc.term
```

We can also weight the matrix by idf values.
```{r}
tfidf <- dfm_tfidf(doc.term)
```


It's often a good idea to take a look at the most frequent words in your corpus.
We can also see the list using `topFeatures`

```{r}
topfeatures(doc.term, 25)
```




As you can see, there are a bunch of stopwords.
Beside the standard stopwords, we also add several things related to web ("http") for example.
(this step does not limit by word frequencies as we did earlier).

```{r}

doc.term <- dfm(twcorpus, remove_punct = TRUE, remove=c(
  stopwords("english"), "movi", "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br"), remove_url=TRUE, verbose=TRUE)

```


## Dictionary methods
Let's try sentiment analysis with dictionary method. First, download [Hu and Liu's opinion lexicon's here](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar). The link is also mentioned in class tutorial.


```{r}
pos.words <- read.csv("opinion-lexicon-English/positive-words.txt",
                 stringsAsFactors = FALSE, header = FALSE)$V1
head(pos.words)

```


```{r}

neg.words <- read.csv("opinion-lexicon-English/negative-words.txt",
                 stringsAsFactors = FALSE, header = FALSE)$V1
head(neg.words)
```


Next, construct a dictionary object.
In this dictionary, there are two keys ("positive" and "negative"), each maps to a list as its values.
(think what Python's dict means; it's similar).

```{r}
mydict <- dictionary(list(positive = pos.words,
                          negative = neg.words))
```

And now we apply it to the corpus in order to count the number of words that appear in each category.
(also remember to do other pre-processing steps, or using the object that's after preprocessing.

```{r}
# sent <- dfm(twcorpus, dictionary = mydict, remove_punct = TRUE, remove=c(
  # stopwords("english"), "the", "t.co", "https", "rt", "amp", "http", "t.c", "can", "u", "<", ">", "br"),remove_url=TRUE, verbose=TRUE)
sent <- dfm(doc.term, dictionary = mydict)
sent
```



We can then extract the score and add it to the data frame as a new variable.
Because the outcome is binary, we coerce the continuous sentiment score into a binary one, if the review has more positive than negative words.


```{r}
reviews$score <- ifelse(as.numeric(sent[,1]) > as.numeric(sent[,2]), 1, 0)
```

## Evaluation

Compare our prediction with that on the true labels. Are our predictions correct?

Before starting, you should always looking at the distribution in outcomes. In this case, it's balanced. So a random guess will yield an accuracy of 0.5.
This is the baseline we want to beat.

Also, here, we are actually not *learning* anything from the training data.
The dictionary is took from somewhere else and it's not related to our training data.
So here, we can calculate performances on the training data.
But for supervised machine learning, it's not recommended to calculate performances on training data; we will still calculate performances on test data.

```{r}
table(reviews$label)
```


First, let us calculate the confusion matrix
```{r}
table(actual = reviews$label, predicted = reviews$score)
```

For positive sentiment:

- accuracy: $\frac{14510 + 14826}{14826+14826+5471+5193} = 0.7276516$
- precision: $\frac{14510}{14826+5193} = 0.7248114$
- recall: $\frac{14510}{14826+5471} = 0.714884$

Not bad!



We can also literally code the math formula in the lecture slides (also in Grimmer and Stewart 2013), which will produce a continuous score 

$$t_i  = \frac{1}{N_i} \sum_{m=1}^M s_m W_{im}$$

```{r}
numerator <- as.numeric(sent[,1]) + -1 * as.numeric(sent[,2])
denominator <- ntoken(doc.term) # or use rowSums(); it's the same
sent_continuous <- numerator/denominator
plot(density(sent_continuous))
```

continuous scale:

- 5: very positive
- -5: very negative

Probability scale:
- 5 -> 0.999 (very likely that it's positive)
- -5 -> 0.001 (very unlikely to be positive)

To do percision-recall curve or ROC curve, we need to transform this continuous variable into a probability scale (within 0 to 1). We do this by using performing a logistic transformation on the sent_continuous, and 
```{r}
sent_prob = plogis(sent_continuous) # probability of being 1 (positive)
reviews$sent_prob = sent_prob
```

We plot the precision-recall positive class, using `PRROC` package.
Read the package's manual and you will find it allows two parameters
- a list of predicted probabilities for actual positive data points
- a list of predicted probabilities for actual negative data points

```{r}
library(PRROC)

reviews.positive <- reviews[reviews$label == 1,]
reviews.negative <- reviews[reviews$label == 0,]
pr <- pr.curve(reviews.positive$sent_prob, reviews.negative$sent_prob, curve = TRUE )
plot(pr)
```

And the same thing for ROC curve
```{r}
roc <- roc.curve(reviews.positive$sent_prob, reviews.negative$sent_prob, curve = TRUE )
plot(roc)
```

In next lectures we will use supervised machine learning algorithms, to see  if we can improve this performance (on the test data, though!).